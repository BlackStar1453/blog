#!/usr/bin/env python3
"""
å¤šæ ‡ç­¾å¤‡å¿˜å½•åŒæ­¥è„šæœ¬
æ”¯æŒè¯†åˆ«å¤šç§æ ‡ç­¾å¹¶è·¯ç”±åˆ°ä¸åŒçš„å¤„ç†è„šæœ¬

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 2.0.0
"""

import os
import re
import json
import subprocess
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Set, Tuple
from dataclasses import dataclass

import urllib.request
import urllib.parse

# åŠ è½½ .env æ–‡ä»¶
def load_env_file(env_path: str = '.env'):
    """åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡"""
    if os.path.exists(env_path):
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

# åœ¨å¯¼å…¥æ—¶åŠ è½½ç¯å¢ƒå˜é‡
load_env_file()

def check_and_install_dependencies():
    """æ£€æŸ¥å¹¶æç¤ºå®‰è£…ä¾èµ–åº“"""
    import sys
    import subprocess

    missing_deps = []

    try:
        import macnotesapp
    except ImportError:
        missing_deps.append("macnotesapp")

    try:
        import rich
    except ImportError:
        missing_deps.append("rich")

    try:
        import markdownify
    except ImportError:
        missing_deps.append("markdownify")

    if missing_deps:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“: {', '.join(missing_deps)}")
        print(f"ğŸ“ å½“å‰Pythonè·¯å¾„: {sys.executable}")
        print(f"ğŸ“ å½“å‰Pythonç‰ˆæœ¬: {sys.version}")
        print()
        print("ğŸ”§ è§£å†³æ–¹æ¡ˆ:")
        print("1. è¿è¡Œè‡ªåŠ¨å®‰è£…è„šæœ¬:")
        print("   ./scripts/setup-dependencies.sh")
        print()
        print("2. æ‰‹åŠ¨å®‰è£…:")
        print(f"   {sys.executable} -m pip install macnotesapp rich markdownify")
        print()
        print("3. å¦‚æœä½¿ç”¨Homebrew Python:")
        print("   /opt/homebrew/bin/python3 -m pip install macnotesapp rich markdownify")
        print("   /opt/homebrew/bin/python3 sync_multi_tag_notes.py")
        exit(1)

# æ£€æŸ¥ä¾èµ–
check_and_install_dependencies()

try:
    from macnotesapp import NotesApp
    from rich.console import Console
    from rich.progress import Progress
    from rich.table import Table
    from rich import print as rprint
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·è¿è¡Œä¾èµ–å®‰è£…è„šæœ¬: ./scripts/setup-dependencies.sh")
    exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('multi_tag_sync.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MastodonPoster:
    """Mastodon å‘å¸–å·¥å…·ï¼ˆä½¿ç”¨æ ‡å‡†åº“å®ç°ï¼‰"""
    def __init__(self):
        self.raw_base = os.getenv("MASTODON_BASE_URL", "")
        self.token = os.getenv("MASTODON_ACCESS_TOKEN", "")
        self.visibility = os.getenv("MASTODON_VISIBILITY", "direct")

    def _instance_origin(self) -> Optional[str]:
        try:
            if not self.raw_base:
                return None
            # å–åè®®+åŸŸåéƒ¨åˆ†ï¼›å¦‚æœä¼ æ¥å¸¦ /home ä¹‹ç±»è·¯å¾„ï¼Œè‡ªåŠ¨æˆªæ–­
            p = urllib.parse.urlparse(self.raw_base)
            if p.scheme and p.netloc:
                return f"{p.scheme}://{p.netloc}"
            # å¦‚æœç›´æ¥æ˜¯åŸŸåæˆ–è£¸è·¯å¾„ï¼Œåšä¸€æ¬¡å…œåº•
            if self.raw_base.startswith("http"):
                return self.raw_base.rstrip("/")
            return f"https://{self.raw_base.strip('/')}"
        except Exception:
            return None

    def post_status(self, text: str) -> bool:
        origin = self._instance_origin()
        if not origin or not self.token:
            return False
        try:
            endpoint = f"{origin}/api/v1/statuses"
            data = urllib.parse.urlencode({
                "status": text,
                "visibility": self.visibility or "public",
                "language": "zh"
            }).encode("utf-8")
            req = urllib.request.Request(endpoint, data=data, method="POST")
            req.add_header("Authorization", f"Bearer {self.token}")
            req.add_header("Content-Type", "application/x-www-form-urlencoded; charset=utf-8")
            with urllib.request.urlopen(req, timeout=10) as resp:
                return 200 <= resp.status < 300
        except Exception as e:
            logger.warning(f"Mastodon API è°ƒç”¨å¤±è´¥: {e}")
            return False

@dataclass
class TaggedNote:
    """å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•æ•°æ®ç»“æ„"""
    id: str
    title: str
    content: str
    tags: List[str]
    primary_tag: str
    creation_date: Optional[datetime]
    modification_date: Optional[datetime]
    account: str
    folder: str

@dataclass
class TagHandler:
    """æ ‡ç­¾å¤„ç†å™¨é…ç½®"""
    type: str
    script: str
    target_path: Optional[str] = None
    target_file: Optional[str] = None
    template: Optional[str] = None
    description: str = ""
    aliases: List[str] = None

class MultiTagSyncer:
    """å¤šæ ‡ç­¾åŒæ­¥å™¨"""

    def __init__(self, config_file: str = "multi_tag_config.json", no_mastodon: bool = False, hashtags_json_path: Optional[str] = None, delete_original: bool = False, auto_extract: bool = True):
        self.console = Console()
        self.config_file = Path(config_file)
        self.state_file = Path("multi_tag_sync_state.json")
        self.processed_notes: Set[str] = set()
        self.notes_app = None
        self.config = {}
        self.tag_handlers = {}
        self.no_mastodon = no_mastodon
        self.hashtags_json_path = hashtags_json_path
        self.hashtags_map: Dict[str, List[str]] = {}
        self.delete_original = delete_original
        self.auto_extract = auto_extract

        # åŠ è½½é…ç½®
        self.load_config()

        # åŠ è½½å·²å¤„ç†çš„å¤‡å¿˜å½•çŠ¶æ€
        self.load_state()

        # å¦‚æœå¯ç”¨è‡ªåŠ¨æå–ä¸”æ²¡æœ‰æä¾› hashtags JSON è·¯å¾„ï¼Œè¿è¡Œ apple_cloud_notes_parser
        if self.auto_extract and not self.hashtags_json_path:
            self.hashtags_json_path = self._run_apple_cloud_notes_parser()

        # åŠ è½½ hashtags æ˜ å°„ï¼ˆå¯é€‰ï¼‰
        if self.hashtags_json_path:
            self._load_hashtags_map()

    def _run_apple_cloud_notes_parser(self) -> Optional[str]:
        """è¿è¡Œ apple_cloud_notes_parser æå–å¤‡å¿˜å½•æ•°æ®"""
        try:
            import subprocess
            import os
            from pathlib import Path

            parser_dir = Path("apple_cloud_notes_parser")
            if not parser_dir.exists():
                logger.warning("apple_cloud_notes_parser ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡è‡ªåŠ¨æå–")
                return None

            self.console.print("ğŸ” æ­£åœ¨è¿è¡Œ Apple Cloud Notes Parser æå–å¤‡å¿˜å½•æ•°æ®...", style="blue")

            # å¤‡å¿˜å½•æ•°æ®è·¯å¾„
            notes_path = Path.home() / "Library/Group Containers/group.com.apple.notes"
            if not notes_path.exists():
                logger.warning(f"å¤‡å¿˜å½•æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {notes_path}")
                return None

            # ä¿å­˜åŸå§‹å·¥ä½œç›®å½•
            original_cwd = os.getcwd()

            # è·å–ç»å¯¹è·¯å¾„
            parser_dir_abs = parser_dir.resolve()

            try:
                # è®¾ç½® Ruby è·¯å¾„ï¼ˆå¦‚æœä½¿ç”¨ Homebrewï¼‰
                env = os.environ.copy()
                if Path("/opt/homebrew/opt/ruby/bin").exists():
                    env["PATH"] = f"/opt/homebrew/opt/ruby/bin:{env.get('PATH', '')}"

                # è¿è¡Œ notes_cloud_ripper.rbï¼ˆåœ¨parserç›®å½•ä¸­ï¼‰
                cmd = [
                    "ruby",
                    str(parser_dir_abs / "notes_cloud_ripper.rb"),
                    "--mac", str(notes_path),
                    "--one-output-folder"
                ]

                result = subprocess.run(
                    cmd,
                    env=env,
                    capture_output=True,
                    text=True,
                    timeout=300,  # 5åˆ†é’Ÿè¶…æ—¶
                    cwd=str(parser_dir_abs)  # åœ¨parserç›®å½•ä¸­æ‰§è¡Œ
                )

                if result.returncode != 0:
                    logger.error(f"apple_cloud_notes_parser æ‰§è¡Œå¤±è´¥: {result.stderr}")
                    return None

                # æŸ¥æ‰¾ç”Ÿæˆçš„ JSON æ–‡ä»¶ï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
                json_dir = parser_dir_abs / "output/notes_rip/json"
                if json_dir.exists():
                    json_files = list(json_dir.glob("all_notes_*.json"))
                    if json_files:
                        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº,ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
                        json_file = sorted(json_files, key=lambda p: p.stat().st_mtime, reverse=True)[0]
                        self.console.print(f"âœ… æˆåŠŸæå–å¤‡å¿˜å½•æ•°æ®: {json_file}", style="green")
                        return str(json_file)

                logger.warning("æœªæ‰¾åˆ°ç”Ÿæˆçš„ JSON æ–‡ä»¶")
                return None

            except Exception as e:
                logger.error(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                return None

        except subprocess.TimeoutExpired:
            logger.error("apple_cloud_notes_parser æ‰§è¡Œè¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"è¿è¡Œ apple_cloud_notes_parser å¤±è´¥: {e}")
            return None

    def load_config(self) -> None:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not self.config_file.exists():
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}")
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}")

        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)

            # è§£ææ ‡ç­¾å¤„ç†å™¨
            for tag, handler_config in self.config.get('tag_handlers', {}).items():
                self.tag_handlers[tag.lower()] = TagHandler(
                    type=handler_config.get('type'),
                    script=handler_config.get('script'),
                    target_path=handler_config.get('target_path'),
                    target_file=handler_config.get('target_file'),
                    template=handler_config.get('template'),
                    description=handler_config.get('description', ''),
                    aliases=[alias.lower() for alias in handler_config.get('aliases', [])]
                )

            logger.info(f"é…ç½®åŠ è½½æˆåŠŸï¼Œæ”¯æŒ {len(self.tag_handlers)} ç§æ ‡ç­¾ç±»å‹")

        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            raise

    def load_state(self) -> None:
        """åŠ è½½å·²å¤„ç†çš„å¤‡å¿˜å½•çŠ¶æ€"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.processed_notes = set(data.get('processed_notes', []))
                logger.info(f"åŠ è½½çŠ¶æ€: å·²å¤„ç† {len(self.processed_notes)} ä¸ªå¤‡å¿˜å½•")
            except Exception as e:
                logger.warning(f"åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
                self.processed_notes = set()

    def save_state(self) -> None:
        """ä¿å­˜å·²å¤„ç†çš„å¤‡å¿˜å½•çŠ¶æ€"""
        try:
            data = {
                'processed_notes': list(self.processed_notes),
                'last_sync': datetime.now().isoformat()
            }
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.debug("çŠ¶æ€å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")

    def clean_state(self, current_note_ids: Set[str]) -> None:
        """æ¸…ç†çŠ¶æ€æ–‡ä»¶ä¸­å·²ä¸å­˜åœ¨çš„å¤‡å¿˜å½• ID"""
        try:
            removed = self.processed_notes - current_note_ids
            if removed:
                logger.info(f"æ¸…ç† {len(removed)} ä¸ªå·²åˆ é™¤å¤‡å¿˜å½•çš„çŠ¶æ€")
                self.processed_notes = self.processed_notes & current_note_ids
                self.save_state()
        except Exception as e:
            logger.error(f"æ¸…ç†çŠ¶æ€å¤±è´¥: {e}")

    def _load_hashtags_map(self) -> None:
        """ä» apple_cloud_notes_parser çš„ all_notes_*.json è¯»å– hashtags æ˜ å°„"""
        try:
            p = Path(self.hashtags_json_path)
            if not p.exists():
                logger.warning(f"hashtags JSON ä¸å­˜åœ¨: {p}")
                return
            with p.open('r', encoding='utf-8') as f:
                data = json.load(f)
            notes = data.get('notes') or {}
            count = 0
            skipped_deleted = 0
            for key, note_obj in notes.items():
                # è·³è¿‡å·²åˆ é™¤æˆ–åœ¨åºŸçº¸ç¯“ä¸­çš„å¤‡å¿˜å½•
                if note_obj.get('trashed') or note_obj.get('deleted'):
                    skipped_deleted += 1
                    continue

                hashtags = note_obj.get('hashtags') or []
                if not hashtags:
                    continue
                norm = [f"#{str(t).strip().lstrip('#').lower()}" for t in hashtags if str(t).strip()]
                keys = set()
                keys.add(str(key))
                for k in ('note_id', 'uuid', 'identifier', 'ZIDENTIFIER'):
                    v = note_obj.get(k)
                    if v:
                        keys.add(str(v))
                for k in keys:
                    self.hashtags_map[k] = norm
                count += 1
            logger.info(f"åŠ è½½ JSON hashtags æ˜ å°„å®Œæˆï¼š{count} æ¡ (è·³è¿‡å·²åˆ é™¤: {skipped_deleted})")
        except Exception as e:
            logger.warning(f"åŠ è½½ JSON hashtags å¤±è´¥: {e}")

    def _read_site_base_url(self) -> str:
        """ä» config.toml è¯»å– base_urlï¼Œç”¨äºæ„é€ æ–‡ç« é“¾æ¥"""
        try:
            cfg = Path("config.toml")
            if not cfg.exists():
                return ""
            text = cfg.read_text(encoding="utf-8", errors="ignore")
            m = re.search(r'^base_url\s*=\s*"([^"]+)"', text, flags=re.MULTILINE)
            return m.group(1).rstrip('/') if m else ""
        except Exception:
            return ""

    def _convert_content_path_to_url(self, created_file_path: Optional[str]) -> Optional[str]:
        """å°† content ä¸‹ç”Ÿæˆçš„ .md æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºç«™ç‚¹ URL"""
        if not created_file_path:
            return None
        try:
            norm = os.path.normpath(created_file_path)
            parts = norm.split(os.sep)
            if "content" not in parts:
                return None
            idx = parts.index("content")
            rel_parts = parts[idx + 1:]
            rel = "/".join(rel_parts)
            if rel.lower().endswith(".md"):
                rel = rel[:-3]
            if rel.endswith("/index"):
                rel = rel[:-len("/index")]
            rel = rel.strip("/")
            url_path = f"/{rel}/" if rel else "/"
            base = getattr(self, "site_base_url", "")
            return f"{base}{url_path}" if base else url_path
        except Exception:
            return None

    def _should_post_to_mastodon(self, tags: List[str]) -> bool:
        """ä»…å½“åŒ…å« #cmx æ ‡ç­¾æ—¶æ‰å…è®¸æ¨é€ Mastodon"""
        try:
            # ç›´æ¥æ£€æŸ¥åŸå§‹æ ‡ç­¾æ ¼å¼ #cmx
            return any((t or '').strip().lower() == '#cmx' for t in (tags or []))
        except Exception:
            return False

    def _has_tag(self, tags: List[str], name: str) -> bool:
        try:
            target = name.strip().lower()
            if not target.startswith('#'):
                target = f"#{target}"
            return any((t or '').strip().lower() == target for t in (tags or []))
        except Exception:
            return False

    def _ensure_markdown_draft(self, file_path: Optional[str]) -> None:
        """åœ¨ç”Ÿæˆçš„ Markdown æ–‡ä»¶ frontmatter ä¸­æ ‡è®° draftï¼ˆæ”¯æŒ YAML '---' ä¸ TOML '+++')."""
        if not file_path:
            return
        p = Path(file_path)
        if not p.exists() or p.suffix.lower() != '.md':
            return
        try:
            text = p.read_text(encoding='utf-8', errors='replace')
            if text.startswith('---'):
                # YAML
                end = text.find('\n---', 3)
                if end != -1:
                    head = text[0:end+4]
                    body = text[end+4:]
                    if re.search(r'^\s*draft\s*:', head, flags=re.IGNORECASE | re.MULTILINE):
                        head = re.sub(r'^(\s*draft\s*:\s*).*$', r'\1true', head, flags=re.IGNORECASE | re.MULTILINE)
                    else:
                        head = head[:-4] + "\ndraft: true\n---"
                    p.write_text(head + body, encoding='utf-8')
                    return
            if text.startswith('+++'):
                # TOML
                end = text.find('\n+++', 3)
                if end != -1:
                    head = text[0:end+4]
                    body = text[end+4:]
                    if re.search(r'^\s*draft\s*=\s*', head, flags=re.IGNORECASE | re.MULTILINE):
                        head = re.sub(r'^(\s*draft\s*=\s*).*$', r'\1true', head, flags=re.IGNORECASE | re.MULTILINE)
                    else:
                        head = head[:-4] + "\ndraft = true\n+++"
                    p.write_text(head + body, encoding='utf-8')
                    return
            # è‹¥æ²¡æœ‰ frontmatterï¼Œåˆ™è¡¥å…… YAML ç®€å•å¤´
            fm = "---\ndraft: true\n---\n\n"
            p.write_text(fm + text, encoding='utf-8')
        except Exception as e:
            logger.warning(f"ä¸º Markdown æ ‡è®° draft å¤±è´¥: {e}")

    def _build_article_status_text(self, title: str, content: str, url: Optional[str]) -> str:
        excerpt = re.sub(r"\s+", " ", content).strip()[:100]
        suffix = f"\n{url}" if url else ""
        text = f"{title}\n\n{excerpt}{'â€¦' if len(content) > 100 else ''}{suffix}"
        # é™åˆ¶é•¿åº¦ï¼Œç•™ä½™é‡
        return text[:480]

    def _post_to_mastodon(self, note_type: str, title: str, content: str, created_file_path: Optional[str]) -> None:
        """æ ¹æ®ç±»å‹å‘å¸–åˆ° Mastodonã€‚thought ç›´æ¥å‘å†…å®¹ï¼Œå…¶ä»–ç±»å‹å‘ æ‘˜è¦+URL"""
        try:
            if not hasattr(self, "mastodon_poster"):
                self.mastodon_poster = MastodonPoster()
            if note_type == "thought":
                text = re.sub(r"\s+", " ", content).strip()[:480]
                if not text:
                    return
                ok = self.mastodon_poster.post_status(text)
                logger.info("Mastodon: å·²å‘å¸ƒ thought å¸–å­" if ok else "Mastodon: thought å‘å¸ƒå¤±è´¥")
            else:
                if not hasattr(self, "site_base_url"):
                    self.site_base_url = self._read_site_base_url()
                url = self._convert_content_path_to_url(created_file_path)
                text = self._build_article_status_text(title, content, url)
                if not text:
                    return
                ok = self.mastodon_poster.post_status(text)
                logger.info("Mastodon: å·²å‘å¸ƒæ–‡ç« æ‘˜è¦" if ok else "Mastodon: æ–‡ç« æ‘˜è¦å‘å¸ƒå¤±è´¥")
        except Exception as e:
            logger.warning(f"Mastodon æ¨é€å¼‚å¸¸: {e}")

    def connect_to_notes(self) -> bool:
        """è¿æ¥åˆ°å¤‡å¿˜å½•åº”ç”¨"""
        try:
            self.notes_app = NotesApp()
            logger.info("æˆåŠŸè¿æ¥åˆ°å¤‡å¿˜å½•åº”ç”¨")
            return True
        except Exception as e:
            logger.error(f"è¿æ¥å¤‡å¿˜å½•åº”ç”¨å¤±è´¥: {e}")
            return False

    def _delete_note_by_id(self, note_id: str) -> bool:
        """é€šè¿‡ AppleScript æŒ‰ id åˆ é™¤å¤‡å¿˜å½•ï¼ˆç§»åŠ¨åˆ°åºŸçº¸ç¯“ï¼‰ã€‚"""
        if not note_id:
            return False
        try:
            script = f'''tell application "Notes"
try
    set theNote to first note whose id is "{note_id}"
    delete theNote
    return "OK"
on error errMsg
    return "ERR:" & errMsg
end try
end tell'''
            result = subprocess.run([
                "osascript", "-e", script
            ], capture_output=True, text=True, encoding='utf-8')
            out = (result.stdout or "").strip()
            if result.returncode == 0 and out == "OK":
                logger.info(f"å·²åˆ é™¤å¤‡å¿˜å½•: {note_id}")
                return True
            logger.warning(f"åˆ é™¤å¤‡å¿˜å½•å¤±è´¥: {note_id} out={out} err={result.stderr}")
            return False
        except Exception as e:
            logger.warning(f"åˆ é™¤å¤‡å¿˜å½•å¼‚å¸¸: {e}")
            return False

    # å·²ç§»é™¤ extract_tags_from_content æ–¹æ³•
    # æ ¹æ®è®¾è®¡è¦æ±‚ï¼Œæ ‡ç­¾åªåº”ä»å¤‡å¿˜å½•å…ƒæ•°æ®å­—æ®µä¸­æå–ï¼Œä¸ä»æ­£æ–‡å†…å®¹è§£æ

    def extract_tags_from_note(self, note) -> List[str]:
        """
        ä»å¤‡å¿˜å½•çš„å…ƒæ•°æ®å­—æ®µä¸­æå–æ ‡ç­¾ã€‚

        è®¾è®¡è¯´æ˜ï¼š
        1. ä¼˜å…ˆä½¿ç”¨ Apple Cloud Notes Parser æä¾›çš„ JSON hashtags æ•°æ®
        2. å¦‚æœæ²¡æœ‰ JSON æ•°æ®ï¼Œåˆ™å°è¯•ä»å¤‡å¿˜å½•å¯¹è±¡çš„å…ƒæ•°æ®å­—æ®µä¸­æå–
        3. ä¸ä»æ­£æ–‡å†…å®¹ä¸­è§£ææ ‡ç­¾ - å¦‚æœå…ƒæ•°æ®ä¸­æ²¡æœ‰æ ‡ç­¾ï¼Œè¯´æ˜è¯¥å¤‡å¿˜å½•ä¸éœ€è¦å¤„ç†

        è¿”å›ï¼šæ ‡ç­¾åˆ—è¡¨ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾åˆ™è¿”å›ç©ºåˆ—è¡¨
        """
        # å¦‚æä¾› JSON æ˜ å°„ï¼Œåˆ™ä»…æŒ‰æ˜ å°„å–å€¼
        if getattr(self, 'hashtags_map', None):
            try:
                candidate_keys: List[str] = []
                for attr in ('id', 'uuid', 'identifier', 'ZIDENTIFIER', 'guid'):
                    v = getattr(note, attr, None)
                    if v:
                        s = str(v)
                        candidate_keys.append(s)
                        m = re.search(r'/ICNote/p(\d+)$', s)
                        if m:
                            candidate_keys.append(m.group(1))
                d = getattr(note, 'asdict', None)
                if callable(d):
                    data = note.asdict() or {}
                    for k in ('note_id', 'uuid', 'identifier', 'ZIDENTIFIER'):
                        v = data.get(k)
                        if v:
                            candidate_keys.append(str(v))
                for k in candidate_keys:
                    if k in self.hashtags_map and self.hashtags_map[k]:
                        tags = [str(t).strip() for t in self.hashtags_map[k] if str(t).strip()]
                        if tags:
                            logger.debug("å·²ä» JSON hashtags è·å–æ ‡ç­¾")
                            return tags
                return []
            except Exception as e:
                logger.debug(f"è¯»å– JSON hashtags å¼‚å¸¸ï¼š{e}")
                return []

        # æœªæä¾› JSONï¼šä»…å°è¯•å…ƒæ•°æ®å­—æ®µï¼ˆä¸å†å›é€€æ­£æ–‡ï¼‰
        tags: List[str] = []
        try:
            d = getattr(note, 'asdict', None)
            if callable(d):
                data = note.asdict() or {}
                for key in ("tags", "hashtags", "note_tags", "labels"):
                    v = data.get(key)
                    if isinstance(v, (list, tuple)):
                        tags = [f"#{str(t).strip().lstrip('#').lower()}" for t in v if str(t).strip()]
                        if tags:
                            break
            if not tags:
                for attr in ("tags", "hashtags", "note_tags", "labels"):
                    if hasattr(note, attr):
                        v = getattr(note, attr)
                        if isinstance(v, (list, tuple)):
                            tags = [f"#{str(t).strip().lstrip('#').lower()}" for t in v if str(t).strip()]
                            if tags:
                                break
        except Exception as e:
            logger.debug(f"ä»å…ƒæ•°æ®æå–æ ‡ç­¾å¼‚å¸¸ï¼š{e}")
        return tags

    def resolve_tag_handler(self, tag: str) -> Optional[TagHandler]:
        """è§£ææ ‡ç­¾å¯¹åº”çš„å¤„ç†å™¨"""
        tag_lower = tag.lower()

        # ç›´æ¥åŒ¹é…
        if tag_lower in self.tag_handlers:
            return self.tag_handlers[tag_lower]

        # åˆ«ååŒ¹é…
        for handler_tag, handler in self.tag_handlers.items():
            if handler.aliases and tag_lower in handler.aliases:
                return handler

        return None

    def get_primary_tag(self, tags: List[str]) -> str:
        """æ ¹æ®ä¼˜å…ˆçº§è·å–ä¸»è¦æ ‡ç­¾"""
        priority_order = self.config.get('processing_options', {}).get('priority_order', [])

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        for priority_tag in priority_order:
            for tag in tags:
                if tag.lower() == priority_tag.lower():
                    return tag

                # æ£€æŸ¥åˆ«å
                handler = self.resolve_tag_handler(tag)
                if handler and priority_tag.lower() in [handler_tag.lower() for handler_tag in self.tag_handlers.keys()]:
                    return tag

        # å¦‚æœæ²¡æœ‰åŒ¹é…ä¼˜å…ˆçº§ï¼Œè¿”å›ç¬¬ä¸€ä¸ªæ ‡ç­¾
        return tags[0] if tags else ""

    def extract_tagged_note(self, note) -> Optional[TaggedNote]:
        """æå–å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•å†…å®¹"""
        try:
            # è·å–å¤‡å¿˜å½•çš„çº¯æ–‡æœ¬å†…å®¹
            content = getattr(note, 'plaintext', '') or getattr(note, 'body', '')
            if not content:
                return None

            # æå–æ ‡ç­¾ï¼ˆä¼˜å…ˆä½¿ç”¨å¤‡å¿˜å½•å…ƒæ•°æ®ä¸­çš„ tag å­—æ®µï¼Œå›é€€åˆ°æ­£æ–‡ #tag è§£æï¼‰
            tags = self.extract_tags_from_note(note)
            if not tags:
                return None

            # è·å–ä¸»è¦æ ‡ç­¾
            primary_tag = self.get_primary_tag(tags)

            # åˆ›å»ºæ ‡ç­¾å¤‡å¿˜å½•å¯¹è±¡
            tagged_note = TaggedNote(
                id=getattr(note, 'id', 'unknown'),
                title=getattr(note, 'name', 'æ— æ ‡é¢˜'),
                content=content,
                tags=tags,
                primary_tag=primary_tag,
                creation_date=getattr(note, 'creation_date', None),
                modification_date=getattr(note, 'modification_date', None),
                account=getattr(note, 'account', 'æœªçŸ¥è´¦æˆ·'),
                folder=getattr(note, 'folder', 'æœªçŸ¥æ–‡ä»¶å¤¹')
            )

            return tagged_note

        except Exception as e:
            logger.warning(f"æå–å¤‡å¿˜å½•å†…å®¹å¤±è´¥: {e}")
            return None

    def clean_content(self, content: str, tags: List[str]) -> str:
        """æ¸…ç†å†…å®¹ï¼Œç§»é™¤æ ‡ç­¾å¹¶æ ¼å¼åŒ–"""
        cleaned_content = content

        # ç§»é™¤æ ‡ç­¾
        if self.config.get('processing_options', {}).get('content_processing', {}).get('remove_tags', True):
            for tag in tags:
                # ç§»é™¤æ ‡ç­¾ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                pattern = re.escape(tag)
                cleaned_content = re.sub(pattern, '', cleaned_content, flags=re.IGNORECASE)

        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        if self.config.get('processing_options', {}).get('content_processing', {}).get('clean_whitespace', True):
            cleaned_content = re.sub(r'\n\s*\n\s*\n', '\n\n', cleaned_content)
            cleaned_content = cleaned_content.strip()
        return cleaned_content

    def _slugify(self, text: str) -> str:
        s = (text or "").strip().lower()
        s = re.sub(r"\s+", "-", s)
        # ä¿ç•™ä¸­æ–‡ã€å­—æ¯æ•°å­—ã€è¿å­—ç¬¦å’Œä¸‹åˆ’çº¿
        s = re.sub(r"[^a-z0-9\-_\u4e00-\u9fff]", "", s)
        return s[:60] or "post"

    def format_date_for_script(self, date: Optional[datetime]) -> Optional[str]:
        """æ ¼å¼åŒ–æ—¥æœŸä¸ºè„šæœ¬å¯æ¥å—çš„æ ¼å¼"""
        if not date:
            return None
        return date.strftime("%Y-%m-%d %H:%M")

    def call_handler_script(self, handler: TagHandler, content: str, tagged_note: TaggedNote) -> Tuple[bool, Optional[str]]:
        """è°ƒç”¨æ ‡ç­¾å¤„ç†è„šæœ¬ï¼Œè¿”å› (æ˜¯å¦æˆåŠŸ, ç”Ÿæˆçš„contentæ–‡ä»¶è·¯å¾„[å¦‚æœå¯è§£æ])"""
        try:
            script_path = Path(handler.script)
            if not script_path.exists():
                logger.error(f"å¤„ç†è„šæœ¬ä¸å­˜åœ¨: {script_path}")
                return False, None

            # æ„å»ºå‘½ä»¤å‚æ•°
            cmd = [str(script_path)]

            # æ ¹æ®å¤„ç†å™¨ç±»å‹æ·»åŠ ä¸åŒçš„å‚æ•°
            if handler.type == "thought":
                # thoughtç±»å‹ï¼šå†…å®¹ + æ—¶é—´
                cmd.append(content)
                date_str = self.format_date_for_script(
                    tagged_note.modification_date or tagged_note.creation_date
                )
                if date_str:
                    cmd.append(date_str)
            else:
                # å…¶ä»–ç±»å‹ï¼šæ ‡é¢˜ + å†…å®¹ï¼ˆé€šè¿‡stdinä¼ é€’ï¼‰
                cmd.append(tagged_note.title)

            # æ‰§è¡Œè„šæœ¬
            if handler.type == "thought":
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    cwd=Path.cwd()
                )
            else:
                result = subprocess.run(
                    cmd,
                    input=content,
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    cwd=Path.cwd()
                )

            created_path = None
            if result.stdout:
                m = re.search(r'(content/[^\s]+?\.md)', result.stdout)
                if m:
                    created_path = os.path.normpath(m.group(1))

            if result.returncode == 0:
                logger.info(f"æˆåŠŸå¤„ç† {handler.type}: {tagged_note.title[:50]}...")
                return True, created_path
            else:
                logger.error(f"å¤„ç† {handler.type} å¤±è´¥: {result.stderr}")
                return False, None

        except Exception as e:
            logger.error(f"è°ƒç”¨å¤„ç†è„šæœ¬å¤±è´¥: {e}")
            return False, None

    def process_default_handler(self, content: str, tagged_note: TaggedNote) -> Tuple[bool, Optional[str]]:
        """æœªçŸ¥æ ‡ç­¾ï¼šç”Ÿæˆä¸€ç¯‡ blog æ–‡ç« ï¼ˆcategories: æ–‡ç« ï¼›tags: åŒ…å«åŸå§‹æ ‡ç­¾ï¼‰"""
        try:
            title = tagged_note.title or "æ— æ ‡é¢˜"
            date = tagged_note.modification_date or tagged_note.creation_date or datetime.now()
            # ä½¿ç”¨å®Œæ•´çš„ ISO 8601 æ ¼å¼
            date_str = date.strftime("%Y-%m-%dT%H:%M:%S+08:00")
            updated_str = date.strftime("%Y-%m-%d")
            slug = self._slugify(title) or date.strftime("%Y%m%d%H%M")
            out_dir = Path("content/blog")
            out_dir.mkdir(parents=True, exist_ok=True)
            filename = f"{date.strftime('%Y-%m-%d')}-{slug}.md"
            out_path = out_dir / filename

            tags = []
            for t in (tagged_note.tags or []):
                tnorm = str(t).strip()
                if not tnorm:
                    continue
                tnorm = tnorm.lstrip('#')
                if tnorm not in tags:
                    tags.append(tnorm)
            if "æ–‡ç« " not in tags:
                tags.insert(0, "æ–‡ç« ")

            draft_line = "draft: true\n" if self._has_tag(tagged_note.tags, '#draft') else ""
            fm = (
                "---\n"
                f"title: \"{title}\"\n"
                f"date: {date_str}\n"
                f"updated: {updated_str}\n"
                f"{draft_line}"
                "taxonomies:\n"
                "  categories:\n"
                "    - æ–‡ç« \n"
                "  tags:\n" +
                "".join([f"    - {t}\n" for t in tags]) +
                "---\n\n"
            )
            body = fm + content.strip() + "\n"
            out_path.write_text(body, encoding='utf-8')
            logger.info(f"é»˜è®¤å¤„ç†ï¼šå·²ç”Ÿæˆ blog æ–‡ç«  {out_path}")
            return True, str(out_path)
        except Exception as e:
            logger.error(f"é»˜è®¤å¤„ç†å¤±è´¥: {e}")
            return False, None

    def get_tagged_notes(self) -> List[TaggedNote]:
        """è·å–æ‰€æœ‰å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•"""
        if not self.notes_app:
            raise RuntimeError("æœªè¿æ¥åˆ°å¤‡å¿˜å½•åº”ç”¨")

        tagged_notes = []

        try:
            all_notes = self.notes_app.notes()
            logger.info(f"æ‰«æ {len(all_notes)} ä¸ªå¤‡å¿˜å½•...")

            for note in all_notes:
                tagged_note = self.extract_tagged_note(note)
                if tagged_note:
                    tagged_notes.append(tagged_note)

            logger.info(f"æ‰¾åˆ° {len(tagged_notes)} ä¸ªå¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•")
            return tagged_notes

        except Exception as e:
            logger.error(f"è·å–å¸¦æ ‡ç­¾å¤‡å¿˜å½•å¤±è´¥: {e}")
            return []

    def sync_notes(self, force: bool = False) -> Dict[str, int]:
        """åŒæ­¥å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•"""
        results = {'success': 0, 'skipped': 0, 'failed': 0, 'unknown_tags': 0}

        # è·å–å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•
        tagged_notes = self.get_tagged_notes()

        if not tagged_notes:
            self.console.print("âŒ æ²¡æœ‰æ‰¾åˆ°å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•", style="yellow")
            return results

        # æ¸…ç†çŠ¶æ€æ–‡ä»¶ä¸­å·²åˆ é™¤çš„å¤‡å¿˜å½•
        current_note_ids = {note.id for note in tagged_notes}
        self.clean_state(current_note_ids)

        # å¤„ç†æ¯ä¸ªå¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•
        with Progress() as progress:
            task = progress.add_task("åŒæ­¥ä¸­...", total=len(tagged_notes))

            for tagged_note in tagged_notes:
                progress.update(task, advance=1)

                # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
                if not force and tagged_note.id in self.processed_notes:
                    logger.debug(f"è·³è¿‡å·²å¤„ç†çš„å¤‡å¿˜å½•: {tagged_note.title}")
                    results['skipped'] += 1
                    continue

                # æ¸…ç†å†…å®¹
                cleaned_content = self.clean_content(tagged_note.content, tagged_note.tags)
                if not cleaned_content:
                    logger.warning(f"å¤‡å¿˜å½•å†…å®¹ä¸ºç©º: {tagged_note.title}")
                    results['skipped'] += 1
                    continue

                # è·å–ä¸»è¦æ ‡ç­¾çš„å¤„ç†å™¨
                handler = self.resolve_tag_handler(tagged_note.primary_tag)

                success, created_path = False, None
                note_type = None
                if handler:
                    # ä½¿ç”¨å¯¹åº”çš„å¤„ç†å™¨
                    success, created_path = self.call_handler_script(handler, cleaned_content, tagged_note)
                    note_type = handler.type
                    if success:
                        self.console.print(
                            f"âœ… å·²åŒæ­¥ [{handler.type}]: {tagged_note.title[:30]}...",
                            style="green"
                        )
                else:
                    # ä½¿ç”¨é»˜è®¤å¤„ç†å™¨
                    success, created_path = self.process_default_handler(cleaned_content, tagged_note)
                    note_type = 'thought'
                    if success:
                        results['unknown_tags'] += 1
                        self.console.print(
                            f"âš ï¸  æœªçŸ¥æ ‡ç­¾ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†: {tagged_note.title[:30]}...",
                            style="yellow"
                        )

                if success:
                    # è‹¥æ ‡è®°ä¸ºè‰ç¨¿ï¼Œåˆ™ç»™ç”Ÿæˆçš„ Markdown æ ‡è®° draft: true
                    if created_path and self._has_tag(tagged_note.tags, '#draft'):
                        self._ensure_markdown_draft(created_path)

                    # æˆåŠŸåå°è¯•æ¨é€åˆ° Mastodonï¼ˆå¤±è´¥ä¸å½±å“æµç¨‹ï¼‰
                    if not self.no_mastodon and self._should_post_to_mastodon(tagged_note.tags):
                        try:
                            self._post_to_mastodon(note_type or 'thought', tagged_note.title, cleaned_content, created_path)
                        except Exception as e:
                            logger.warning(f"Mastodon æ¨é€å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰ï¼š{e}")
                    else:
                        logger.info("è·³è¿‡ Mastodon å‘å¸ƒï¼ˆæœªåŒ…å« #cmx æˆ– --no-mastodon å·²å¯ç”¨ï¼‰")

                    self.processed_notes.add(tagged_note.id)
                    results['success'] += 1

                    # æˆåŠŸååˆ é™¤æºå¤‡å¿˜å½•ï¼ˆå— --delete-original æ§åˆ¶ï¼‰
                    if self.delete_original:
                        try:
                            if self._delete_note_by_id(tagged_note.id):
                                logger.info(f"å·²æ¸…ç†æºå¤‡å¿˜å½•: {tagged_note.title[:50]}")
                            else:
                                logger.warning(f"æœªèƒ½åˆ é™¤æºå¤‡å¿˜å½•ï¼ˆå°†ä¿ç•™ï¼‰: {tagged_note.title[:50]}")
                        except Exception as e:
                            logger.warning(f"åˆ é™¤æºå¤‡å¿˜å½•å¼‚å¸¸: {e}")
                    else:
                        logger.debug("æœªå¼€å¯ --delete-originalï¼Œä¿ç•™æºå¤‡å¿˜å½•")
                else:
                    results['failed'] += 1
                    self.console.print(
                        f"âŒ åŒæ­¥å¤±è´¥: {tagged_note.title[:30]}...",
                        style="red"
                    )

        # ä¿å­˜çŠ¶æ€
        self.save_state()

        return results

    def list_tagged_notes(self) -> None:
        """åˆ—å‡ºæ‰€æœ‰å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•"""
        tagged_notes = self.get_tagged_notes()

        if not tagged_notes:
            self.console.print("âŒ æ²¡æœ‰æ‰¾åˆ°å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•", style="yellow")
            return

        # æŒ‰æ ‡ç­¾ç±»å‹åˆ†ç»„
        notes_by_type = {}
        for note in tagged_notes:
            handler = self.resolve_tag_handler(note.primary_tag)
            note_type = handler.type if handler else "unknown"

            if note_type not in notes_by_type:
                notes_by_type[note_type] = []
            notes_by_type[note_type].append(note)

        self.console.print(f"\nğŸ“‹ æ‰¾åˆ° {len(tagged_notes)} ä¸ªå¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•:\n", style="bold blue")

        for note_type, notes in notes_by_type.items():
            # åˆ›å»ºè¡¨æ ¼
            table = Table(title=f"{note_type.upper()} ({len(notes)} ä¸ª)")
            table.add_column("æ ‡é¢˜", style="cyan", no_wrap=False)
            table.add_column("æ ‡ç­¾", style="magenta")
            table.add_column("çŠ¶æ€", style="green")
            table.add_column("ä¿®æ”¹æ—¶é—´", style="dim")

            for note in notes:
                status = "âœ… å·²å¤„ç†" if note.id in self.processed_notes else "â³ å¾…å¤„ç†"
                mod_time = note.modification_date.strftime('%Y-%m-%d %H:%M') if note.modification_date else "æœªçŸ¥"

                table.add_row(
                    note.title[:40] + "..." if len(note.title) > 40 else note.title,
                    ", ".join(note.tags),
                    status,
                    mod_time
                )

            self.console.print(table)
            self.console.print()

    def list_supported_tags(self) -> None:
        """åˆ—å‡ºæ”¯æŒçš„æ ‡ç­¾ç±»å‹"""
        self.console.print("\nğŸ·ï¸  æ”¯æŒçš„æ ‡ç­¾ç±»å‹:\n", style="bold blue")

        table = Table()
        table.add_column("æ ‡ç­¾", style="cyan")
        table.add_column("ç±»å‹", style="magenta")
        table.add_column("æè¿°", style="white")
        table.add_column("åˆ«å", style="dim")

        for tag, handler in self.tag_handlers.items():
            aliases = ", ".join(handler.aliases) if handler.aliases else "æ— "
            table.add_row(
                tag,
                handler.type,
                handler.description,
                aliases
            )

        self.console.print(table)

        # æ˜¾ç¤ºé»˜è®¤å¤„ç†å™¨
        default_config = self.config.get('default_handler', {})
        if default_config:
            self.console.print(f"\nğŸ”§ é»˜è®¤å¤„ç†å™¨: {default_config.get('description', 'æœªçŸ¥')}", style="yellow")

    def reset_state(self) -> None:
        """é‡ç½®å¤„ç†çŠ¶æ€"""
        self.processed_notes.clear()
        if self.state_file.exists():
            self.state_file.unlink()
        self.console.print("âœ… å·²é‡ç½®å¤„ç†çŠ¶æ€", style="green")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(
        description="åŒæ­¥macOSå¤‡å¿˜å½•ä¸­å¸¦æ ‡ç­¾çš„å†…å®¹åˆ°å¯¹åº”çš„ç¬”è®°ç±»å‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŒæ­¥æ–°çš„å¸¦æ ‡ç­¾å¤‡å¿˜å½•
  python3 sync_multi_tag_notes.py

  # åˆ—å‡ºæ‰€æœ‰å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•
  python3 sync_multi_tag_notes.py --list

  # åˆ—å‡ºæ”¯æŒçš„æ ‡ç­¾ç±»å‹
  python3 sync_multi_tag_notes.py --tags

  # å¼ºåˆ¶é‡æ–°åŒæ­¥æ‰€æœ‰å¤‡å¿˜å½•
  python3 sync_multi_tag_notes.py --force

  # é‡ç½®å¤„ç†çŠ¶æ€
  python3 sync_multi_tag_notes.py --reset
        """
    )

    parser.add_argument(
        '--list', '-l',
        action='store_true',
        help='åˆ—å‡ºæ‰€æœ‰å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•'
    )

    parser.add_argument(
        '--tags', '-t',
        action='store_true',
        help='åˆ—å‡ºæ”¯æŒçš„æ ‡ç­¾ç±»å‹'
    )

    parser.add_argument(
        '--force', '-f',
        action='store_true',
        help='å¼ºåˆ¶é‡æ–°åŒæ­¥æ‰€æœ‰å¤‡å¿˜å½•ï¼ˆå¿½ç•¥å·²å¤„ç†çŠ¶æ€ï¼‰'
    )

    parser.add_argument(
        '--reset', '-r',
        action='store_true',
        help='é‡ç½®å¤„ç†çŠ¶æ€'
    )

    parser.add_argument(
        '--config', '-c',
        default='multi_tag_config.json',
        help='é…ç½®æ–‡ä»¶è·¯å¾„'
    )

    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='è¯¦ç»†è¾“å‡º'
    )

    parser.add_argument(
        '--no-mastodon',
        action='store_true',
        help='è·³è¿‡ Mastodon å‘å¸ƒ'
    )
    parser.add_argument(
        '--hashtags-json',
        default=None,
        help='apple_cloud_notes_parser å¯¼å‡ºçš„ all_notes_*.json è·¯å¾„ï¼Œç”¨äºä¼˜å…ˆè¯»å– hashtags'
    )

    parser.add_argument(
        '--no-auto-extract',
        action='store_true',
        help='ç¦ç”¨è‡ªåŠ¨è¿è¡Œ apple_cloud_notes_parser æå–å¤‡å¿˜å½•æ•°æ®'
    )

    # åˆ é™¤å¼€å…³ï¼šé»˜è®¤ä¸åˆ é™¤ï¼›--delete-original å¼€å¯åˆ é™¤ï¼›--no-delete-original å…³é—­
    delete_group = parser.add_mutually_exclusive_group()
    delete_group.add_argument('--delete-original', dest='delete_original', action='store_true', help='æˆåŠŸå¤„ç†ååˆ é™¤åŸå§‹å¤‡å¿˜å½•ï¼ˆç§»å…¥åºŸçº¸ç¯“ï¼‰')
    delete_group.add_argument('--no-delete-original', dest='delete_original', action='store_false', help='æˆåŠŸå¤„ç†åä¿ç•™åŸå§‹å¤‡å¿˜å½•ï¼ˆé»˜è®¤ï¼‰')
    parser.set_defaults(delete_original=False)

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    console = Console()

    try:
        # åˆå§‹åŒ–åŒæ­¥å™¨
        syncer = MultiTagSyncer(
            config_file=args.config,
            no_mastodon=args.no_mastodon,
            hashtags_json_path=args.hashtags_json,
            delete_original=args.delete_original,
            auto_extract=not args.no_auto_extract
        )

        # é‡ç½®çŠ¶æ€
        if args.reset:
            syncer.reset_state()
            return 0

        # åˆ—å‡ºæ”¯æŒçš„æ ‡ç­¾
        if args.tags:
            syncer.list_supported_tags()
            return 0

        # è¿æ¥åˆ°å¤‡å¿˜å½•åº”ç”¨
        console.print("ğŸ”— è¿æ¥åˆ°å¤‡å¿˜å½•åº”ç”¨...", style="blue")
        if not syncer.connect_to_notes():
            console.print("âŒ è¿æ¥å¤±è´¥", style="red")
            return 1

        # åˆ—å‡ºå¤‡å¿˜å½•
        if args.list:
            syncer.list_tagged_notes()
            return 0

        # åŒæ­¥å¤‡å¿˜å½•
        console.print("ğŸ”„ å¼€å§‹åŒæ­¥å¸¦æ ‡ç­¾çš„å¤‡å¿˜å½•...", style="bold green")
        results = syncer.sync_notes(force=args.force)

        # æ˜¾ç¤ºç»“æœ
        console.print("\nâœ… åŒæ­¥å®Œæˆ!", style="bold green")
        console.print(f"   æˆåŠŸ: {results['success']} ä¸ª", style="green")
        console.print(f"   è·³è¿‡: {results['skipped']} ä¸ª", style="yellow")
        console.print(f"   å¤±è´¥: {results['failed']} ä¸ª", style="red")
        if results['unknown_tags'] > 0:
            console.print(f"   æœªçŸ¥æ ‡ç­¾: {results['unknown_tags']} ä¸ª", style="cyan")

        return 0

    except KeyboardInterrupt:
        console.print("\nâŒ ç”¨æˆ·ä¸­æ–­", style="red")
        return 1
    except Exception as e:
        console.print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}", style="red")
        logger.exception("ç¨‹åºæ‰§è¡Œå‡ºé”™")
        return 1


if __name__ == "__main__":
    exit(main())
